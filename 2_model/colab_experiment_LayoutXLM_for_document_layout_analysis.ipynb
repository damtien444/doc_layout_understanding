{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7G7Ye4s5GlE4",
    "outputId": "e9a2d98d-9030-4e27-8342-8c4195d920ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Installing build dependencies ... \u001B[?25l\u001B[?25hdone\n",
      "  Getting requirements to build wheel ... \u001B[?25l\u001B[?25hcanceled\u001B[31mERROR: Operation cancelled by user\u001B[0m\u001B[31m\n",
      "\u001B[0m\u001B[31mERROR: Operation cancelled by user\u001B[0m\u001B[31m\n",
      "\u001B[0m\u001B[31mERROR: Operation cancelled by user\u001B[0m\u001B[31m\n",
      "\u001B[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q git+https://github.com/huggingface/transformers.git\n",
    "!pip install -q datasets seqeval\n",
    "!python -m pip install -q 'git+https://github.com/facebookresearch/detectron2.git'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pDKKSycafzNz",
    "outputId": "8ac4bb2d-6fc6-4afe-8633-9b138453d6ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.8/dist-packages (1.9.3)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (4.5.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.6.0.post0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (0.7.1)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (4.64.1)\n",
      "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (23.0)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (1.22.4)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (1.13.1+cu116)\n",
      "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (2023.1.0)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (0.11.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (3.8.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (2.25.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (22.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (4.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (3.0.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.8.2)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (1.26.14)\n",
      "\u001B[31mERROR: Operation cancelled by user\u001B[0m\u001B[31m\n",
      "\u001B[0m"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-lightning\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LgBBfYdh6Ee1"
   },
   "outputs": [],
   "source": [
    "!sudo add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
    "!sudo apt-get update -qq 2>&1 > /dev/null\n",
    "!sudo apt -y install -qq google-drive-ocamlfuse 2>&1 > /dev/null\n",
    "!google-drive-ocamlfuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qWemUQZFC77L"
   },
   "outputs": [],
   "source": [
    "!sudo apt-get install -qq w3m # to act as web browser \n",
    "!xdg-settings set default-web-browser w3m.desktop # to set default browser\n",
    "%cd /content\n",
    "!mkdir drive\n",
    "%cd drive\n",
    "!mkdir MyDrive\n",
    "%cd ..\n",
    "%cd ..\n",
    "!google-drive-ocamlfuse /content/drive/MyDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-htzWDBJDBOG"
   },
   "outputs": [],
   "source": [
    "! cp /content/drive/MyDrive/DocRec/artifact/2_selected_sample_for_DCU_model.zip /content/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WgBAz5nnEaNZ"
   },
   "outputs": [],
   "source": [
    "! cp \"/content/drive/MyDrive/DocRec/artifact/1000DataForOCR_fineLabel_dataset_coco_1.json\" /content/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "88PfGjM3DQG_"
   },
   "outputs": [],
   "source": [
    "! unzip /content/2_selected_sample_for_DCU_model.zip -d /content/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kY5KCeHEF0ja"
   },
   "outputs": [],
   "source": [
    "from google.colab.patches import cv2_imshow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ff_6QDFgMRvb",
    "outputId": "63b93859-a083-484a-adfe-4a3ec3353904"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tiendq/.local/lib/python3.8/site-packages/transformers/models/layoutlmv2/feature_extraction_layoutlmv2.py:30: FutureWarning: The class LayoutLMv2FeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use LayoutLMv2ImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import LayoutXLMProcessor\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "\n",
    "processor = LayoutXLMProcessor.from_pretrained(\n",
    "    \"microsoft/layoutxlm-base\", \n",
    "    apply_ocr=False, \n",
    "    only_label_first_subword=False, \n",
    "    is_split_into_words=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dcRlvaJ2DlHt",
    "outputId": "856b64b1-74a9-4f78-aee7-1d9ad50e56e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.49s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from enum import Enum\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from pycocotools.coco import COCO\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "color_map = {4: (0, 0, 0), 5: (255, 0, 0), 6: (0, 255, 0), 21: (0, 0, 255),\n",
    "             22: (255, 255, 0), 23: (0, 255, 255), 24: (255, 0, 255), 25: (128, 128, 128),\n",
    "             26: (192, 192, 192), 10: (64, 64, 64)}\n",
    "\n",
    "label_list = ['title', 'explanation', 'answer', 'super_title', 'header', 'footer', 'ending', 'heading', 'starting']\n",
    "\n",
    "def normalize_bbox(bbox, width, height):\n",
    "    return [\n",
    "        int(1000 * (bbox[0] / width)),\n",
    "        int(1000 * (bbox[1] / height)),\n",
    "        int(1000 * (bbox[2] / width)),\n",
    "        int(1000 * (bbox[3] / height)),\n",
    "    ]\n",
    "\n",
    "\n",
    "def unnormalize_bbox(nbbox, width, height):\n",
    "  return [\n",
    "      int((nbbox[0] * width) / 1000),\n",
    "      int((nbbox[1] * height) / 1000),\n",
    "      int((nbbox[2] * width) / 1000),\n",
    "      int((nbbox[3] * height) / 1000),\n",
    "  ]\n",
    "\n",
    "\n",
    "class CocoDataset(Dataset):\n",
    "    def __init__(self, root_dir, annotation_file):\n",
    "        self.root_dir = root_dir\n",
    "        self.annotation_file = annotation_file\n",
    "\n",
    "        self.coco = COCO(annotation_file)\n",
    "        self.image_ids = list(sorted(self.coco.imgs.keys()))\n",
    "        self.label_list = label_list\n",
    "        self.label2CVATid = {self.coco.cats[_id]['name']: _id for _id in self.coco.cats.keys()}\n",
    "        self.CVATid2label = {_id: self.coco.cats[_id]['name'] for _id in self.coco.cats.keys()}\n",
    "\n",
    "        self.label2id = {label: idx for idx, label in enumerate(label_list)}\n",
    "        self.id2label = {idx: label for idx, label in enumerate(label_list)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.image_ids[idx]\n",
    "        img_info = self.coco.loadImgs(img_id)[0]\n",
    "        img_path = os.path.join(self.root_dir, img_info['file_name'])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        annotations_ids = self.coco.getAnnIds(imgIds=img_info['id'])\n",
    "        annotations = self.coco.loadAnns(annotations_ids)\n",
    "        # target['boxes'] = torch.Tensor([ann['bbox'] for ann in annotations])\n",
    "        # target['labels'] = torch.LongTensor([ann['category_id'] for ann in annotations])\n",
    "\n",
    "        bboxes = []\n",
    "        labels_id = []\n",
    "        words = []\n",
    "        for ann in annotations:\n",
    "\n",
    "            coco2normalbbox = [ann['bbox'][0], ann['bbox'][1], ann['bbox'][0] + ann['bbox'][2], ann['bbox'][1] + ann['bbox'][3]]\n",
    "\n",
    "            # skip instance that is other than the label list in this problem\n",
    "            try:\n",
    "                box = normalize_bbox(coco2normalbbox, image.width, image.height)\n",
    "                label_id = self.label2id[self.CVATid2label[ann['category_id']]]\n",
    "                word = ann['attributes']['value']\n",
    "            except KeyError:\n",
    "                continue\n",
    "\n",
    "            bboxes.append(box)\n",
    "\n",
    "            labels_id.append(label_id)\n",
    "\n",
    "            words.append(word)\n",
    "\n",
    "        # return image, annotations\n",
    "        # print(type(words), words)\n",
    "        # encoding = processor(\n",
    "        #     np.array(image), \n",
    "        #     words,\n",
    "        #     boxes=torch.tensor(bboxes),\n",
    "        #     word_labels=torch.tensor(labels_id),\n",
    "        #     max_length=512,\n",
    "        #     truncation=True,\n",
    "        #     padding=\"max_length\",\n",
    "        #     # pad_to_multiple_of=8,\n",
    "        #     return_tensors=\"pt\"\n",
    "        # )\n",
    "\n",
    "        # return encoding\n",
    "        # return dict(\n",
    "        #     input_ids=encoding['input_ids'].flatten(),\n",
    "        #     attention_mask=encoding['attention_mask'].flatten(),\n",
    "        #     bbox=encoding['bbox'].flatten(end_dim=1),\n",
    "        #     image=encoding['image'].flatten(end_dim=1),\n",
    "        #     labels=encoding['labels'].flatten()\n",
    "        # )\n",
    "\n",
    "        # print(img_info)\n",
    "        return {'words':words, 'boxes':bboxes, 'labels_id': labels_id, 'id': img_info['id'], 'width': img_info['width'], 'height': img_info['height'], 'image_path': self.root_dir + os.sep+ img_info['file_name']}\n",
    "\n",
    "    def draw_example(self, words, boxes, labels_id, width, height, file_name, **kwargs):\n",
    "        # Convert the image to a NumPy array and draw the annotations using cv2\n",
    "        # self.root_dir\n",
    "        image = Image.open(self.root_dir+os.sep+file_name).convert('RGB')\n",
    "        image = np.array(image)\n",
    "        for i in range(len(boxes)):\n",
    "            bbox = boxes[i]\n",
    "            bbox = unnormalize_bbox(bbox, width, height)\n",
    "\n",
    "            cvatId = self.label2CVATid[self.id2label[labels_id[i]]]\n",
    "            color = color_map.get(cvatId)\n",
    "\n",
    "            cv2.rectangle(image, (int(bbox[0]), int(bbox[1])),\n",
    "                          (int(bbox[2]), int(bbox[3])),\n",
    "                          color, thickness=1)\n",
    "            label = self.coco.loadCats(cvatId)[0][\"name\"]\n",
    "            cv2.putText(image, label, (int(bbox[0]), int(bbox[1] - 2)), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        fontScale=0.25, color=(0, 0, 255), thickness=1)\n",
    "\n",
    "        return image\n",
    "        # cv2.imshow(\"Image with Annotations\", image_np)\n",
    "        # cv2.waitKey(0)\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "root = \"/home/tiendq/document-layout-analysis/0_data_repository/2_selected_sample\"\n",
    "ann_file = \"/home/tiendq/document-layout-analysis/0_data_repository/1000DataForOCR_fineLabel_dataset_coco.json\"\n",
    "torch_dataset = CocoDataset(root, ann_file)\n",
    "# dataset[0]\n",
    "# print(len(dataset))\n",
    "# cv2_imshow(dataset.draw_example(**dataset[57]))\n",
    "# print(dataset.draw_example(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zSCAzcFJiLI2"
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# list_of_records = []\n",
    "# for i in range(len(dataset)):\n",
    "#     list_of_records.append(dataset[i])\n",
    "\n",
    "# df = pd.DataFrame(list_of_records)\n",
    "# # df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D2irKmwuWTQA"
   },
   "outputs": [],
   "source": [
    "# train_size = int(0.8 * len(torch_dataset))\n",
    "# test_size = len(torch_dataset) - train_size\n",
    "# train_ds, test_ds = torch.utils.data.random_split(torch_dataset, [train_size, test_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72,
     "referenced_widgets": [
      "5143080630f54727b49f868fd302a91e",
      "aa36543bf5294b4a92b4e00c2b279a4d",
      "c1792af7961b4d9cb035bc3129e3208f",
      "dc32e008b1c84ba197478f6bdd37ed59",
      "dc68b7652f4e4111b4d368da5d094336",
      "d024e956ca494e338e7afd87f34df4d1",
      "e1f589b118e144398e026ac3c9570395",
      "379c0138babd4a778a2ef255066a44da",
      "8ae95afd37ac4b339c2047a9d0c2cdce",
      "171b5ee60e9d45b5a0427b19360edb51",
      "5fcf5d8fa44642ab904531bf0d72bf03"
     ]
    },
    "id": "m41HoGkvsbhd",
    "outputId": "d06cf8df-ccc5-4eab-89b5-268ed4651965"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset generator (/home/tiendq/.cache/huggingface/datasets/generator/default-39aee09cfd40e826/0.0.0)\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "# ds = Dataset.from_pandas(df)\n",
    "\n",
    "def to_dataset():\n",
    "\n",
    "    # for i in range(len(torch_dataset)):\n",
    "    for i in range(100):\n",
    "\n",
    "        yield torch_dataset[i]\n",
    "\n",
    "ds = Dataset.from_generator(to_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "4eiASvXwAaZb"
   },
   "outputs": [],
   "source": [
    "ds = ds.train_test_split(test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dIDqhNO01wkd",
    "outputId": "29e8c380-acbb-4a4b-d7ec-a28e0b9094d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['words', 'boxes', 'labels_id', 'id', 'width', 'height', 'image_path'],\n",
       "        num_rows: 80\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['words', 'boxes', 'labels_id', 'id', 'width', 'height', 'image_path'],\n",
       "        num_rows: 20\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "XSgMSX1fv-qM"
   },
   "outputs": [],
   "source": [
    "features = ds[\"train\"].features\n",
    "column_names = ds[\"train\"].column_names\n",
    "image_column_name = \"image\"\n",
    "text_column_name = \"words\"\n",
    "boxes_column_name = \"boxes\"\n",
    "label_column_name = \"labels_id\"\n",
    "\n",
    "\n",
    "def prepare_examples(examples):\n",
    "    images = [Image.open(path).convert(\"RGB\") for path in examples['image_path']] \n",
    "    words = examples[text_column_name]\n",
    "    boxes = examples[boxes_column_name]\n",
    "    word_labels = examples[label_column_name]\n",
    "    encoding = processor(images, words, boxes=boxes, word_labels=word_labels, truncation=True, stride =128, \n",
    "         padding=\"max_length\", max_length=512, pad_token_label = -100, return_overflowing_tokens=True, return_offsets_mapping=True)\n",
    "    offset_mapping = encoding.pop('offset_mapping')\n",
    "    overflow_to_sample_mapping = encoding.pop('overflow_to_sample_mapping')\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "b8640fb1d1b8455598fd47ffd95c6d73",
      "f41338268d364733a54fdaae085a0711",
      "3a8fedc7f66348df97247a996e4db1e7",
      "0296db9d5a744384b4395a10d0ff4251",
      "5f6cd659aea84ac3bdd429d8726f17e6",
      "4e351492630e4bc59c9b64f126a3d1e9",
      "56e17d1cb5214f78932769d664f661eb",
      "1e30f810b1c64ceda9a218442e068d7f",
      "797674d4425c4b40bccc4df616209fd8",
      "3b07b28de74a4d1eaefb4939a9cb1e2c",
      "0cf548ff584c4b3a9685549a8733712b",
      "2e9b8d589e42444194cb25f3482bdd26",
      "c94c13ef0c8b4f589e296848795a3495",
      "9bee760419674598a85b98014ccc38e7",
      "6bf4efbcaad84a3c86bde13653f6acd4",
      "556f717f09b64019be2719550e8f92e9",
      "0ae4e029300944e9b0ba92e858a75858",
      "5b53942300de4e47884f6855dba71774",
      "fddaa84bee894e4091ff90646ced1538",
      "0eb83ba3cf5f426284af3b3ef8945ae9",
      "20d07a579faa47819ee5d88fe573410c",
      "c0cbe38de2724c0ebe8d59c6317721e3"
     ]
    },
    "id": "fmfVnzuwwKdc",
    "outputId": "99729d85-b119-44f4-ec64-278836ea7235"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ab36798b68846a093b97455e085a660",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/80 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e92dfd2bbffc493fbe05d4528f9f56e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Features, Sequence, ClassLabel, Value, Array2D, Array3D\n",
    "\n",
    "# we need to define custom features for `set_format` (used later on) to work properly\n",
    "features = Features({\n",
    "    'image': Array3D(dtype=\"float32\", shape=(3, 224, 224)),\n",
    "    'input_ids': Sequence(feature=Value(dtype='int64')),\n",
    "    'attention_mask': Sequence(Value(dtype='int64')),\n",
    "    'bbox': Array2D(dtype=\"int64\", shape=(512, 4)),\n",
    "    'labels': Sequence(feature=Value(dtype='int64')),\n",
    "})\n",
    "\n",
    "train_dataset =  ds[\"train\"].map(\n",
    "    prepare_examples,\n",
    "    batched=True,\n",
    "    remove_columns=column_names,\n",
    "    features=features,\n",
    ")\n",
    "eval_dataset = ds[\"test\"].map(\n",
    "    prepare_examples,\n",
    "    batched=True,\n",
    "    remove_columns=column_names,\n",
    "    features=features,\n",
    ")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xhl5lXypEq2l",
    "outputId": "4f27af02-89d8-4967-b7d4-585a40bfbd7c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'input_ids', 'attention_mask', 'bbox', 'labels'],\n",
       "    num_rows: 5\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k2zzFtP7JjZs",
    "outputId": "6dd53943-dfc4-448d-fd24-76430b1242b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'input_ids', 'attention_mask', 'bbox', 'labels'],\n",
       "    num_rows: 19\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "RaM4k5OlB5bP"
   },
   "outputs": [],
   "source": [
    "train_dataset.set_format(\"torch\")\n",
    "eval_dataset.set_format(\"torch\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ROCeOdagDpZB"
   },
   "outputs": [],
   "source": [
    "from transformers import LayoutLMv2ForTokenClassification, LayoutXLMProcessor\n",
    "import copy\n",
    "import torch\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lQGwsQlAUsSX",
    "outputId": "53ed2e25-42d9-4d73-c538-94b57ae8a152"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/layoutxlm-base were not used when initializing LayoutLMv2ForTokenClassification: ['layoutlmv2.visual.backbone.bottom_up.res4.14.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.1.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.1.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.16.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.1.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.4.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.12.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.15.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.16.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.18.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.0.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.3.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.0.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.21.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.12.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.0.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.13.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.7.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.8.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.3.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.2.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.17.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.1.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.4.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.6.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.stem.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.7.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.2.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.11.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.0.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.3.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.1.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.2.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.15.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.13.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.0.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.2.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.10.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.1.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.0.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.2.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.4.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.19.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.17.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.8.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.5.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.1.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.3.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.7.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.1.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.15.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.9.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.0.shortcut.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.11.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.0.shortcut.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.0.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.17.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.22.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.2.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.22.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.20.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.10.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.0.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.22.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.5.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.20.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.1.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.0.shortcut.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.3.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.2.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.6.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.3.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.6.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.0.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.21.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.12.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.14.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.5.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.9.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.19.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.11.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.19.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.0.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.2.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.2.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.2.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.9.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.10.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.2.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.0.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.0.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.0.shortcut.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.1.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.8.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.1.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.13.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.16.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.20.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.1.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.14.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.18.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.18.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.21.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.2.conv1.norm.num_batches_tracked']\n",
      "- This IS expected if you are initializing LayoutLMv2ForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LayoutLMv2ForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LayoutLMv2ForTokenClassification were not initialized from the model checkpoint at microsoft/layoutxlm-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = LayoutLMv2ForTokenClassification.from_pretrained('microsoft/layoutxlm-base', num_labels=len(torch_dataset.label_list), id2label=torch_dataset.id2label, label2id=torch_dataset.label2id)\n",
    "\n",
    "# processor = LayoutXLMProcessor.from_pretrained(\"microsoft/layoutxlm-base\", apply_ocr=False, only_label_first_subword=False, is_split_into_words=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LAo1wM9BxckT",
    "outputId": "1d4c6e09-b07d-47df-d9b8-d1c03f405a76"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"seqeval\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [\"I-\"+torch_dataset.label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [\"I-\"+torch_dataset.label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "\n",
    "    no_flatten = ['overall_precision', \"overall_recall\", 'overall_f1', 'overall_accuracy']\n",
    "    to_be_flatten = []\n",
    "    for key, val in results.items():\n",
    "        if key in no_flatten:\n",
    "            continue\n",
    "        to_be_flatten.append(key)\n",
    "    \n",
    "    for key in to_be_flatten:\n",
    "        print(key)\n",
    "        val = results[key]\n",
    "        for metr, value in val.items():\n",
    "            results[key+\"_\"+metr] = value\n",
    "        del results[key]\n",
    "\n",
    "    return results\n",
    "    # return {\n",
    "    #     \"precision\": results[\"overall_precision\"],\n",
    "    #     \"recall\": results[\"overall_recall\"],\n",
    "    #     \"f1\": results[\"overall_f1\"],\n",
    "    #     \"accuracy\": results[\"overall_accuracy\"],\n",
    "    # }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "M5d8ywZEIpiA"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "id": "3b6O3EMUU3N0",
    "outputId": "b49a74a2-3ce5-4c56-ec6a-6015b2600d47"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='340' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 71/340 00:37 < 02:25, 1.85 it/s, Epoch 2.06/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Overall Precision</th>\n",
       "      <th>Overall Recall</th>\n",
       "      <th>Overall F1</th>\n",
       "      <th>Overall Accuracy</th>\n",
       "      <th>Answer Precision</th>\n",
       "      <th>Answer Recall</th>\n",
       "      <th>Answer F1</th>\n",
       "      <th>Answer Number</th>\n",
       "      <th>Ending Precision</th>\n",
       "      <th>Ending Recall</th>\n",
       "      <th>Ending F1</th>\n",
       "      <th>Ending Number</th>\n",
       "      <th>Explanation Precision</th>\n",
       "      <th>Explanation Recall</th>\n",
       "      <th>Explanation F1</th>\n",
       "      <th>Explanation Number</th>\n",
       "      <th>Footer Precision</th>\n",
       "      <th>Footer Recall</th>\n",
       "      <th>Footer F1</th>\n",
       "      <th>Footer Number</th>\n",
       "      <th>Header Precision</th>\n",
       "      <th>Header Recall</th>\n",
       "      <th>Header F1</th>\n",
       "      <th>Header Number</th>\n",
       "      <th>Heading Precision</th>\n",
       "      <th>Heading Recall</th>\n",
       "      <th>Heading F1</th>\n",
       "      <th>Heading Number</th>\n",
       "      <th>Starting Precision</th>\n",
       "      <th>Starting Recall</th>\n",
       "      <th>Starting F1</th>\n",
       "      <th>Starting Number</th>\n",
       "      <th>Super Title Precision</th>\n",
       "      <th>Super Title Recall</th>\n",
       "      <th>Super Title F1</th>\n",
       "      <th>Super Title Number</th>\n",
       "      <th>Title Precision</th>\n",
       "      <th>Title Recall</th>\n",
       "      <th>Title F1</th>\n",
       "      <th>Title Number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.618000</td>\n",
       "      <td>1.693942</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.422444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.800800</td>\n",
       "      <td>1.557736</td>\n",
       "      <td>0.006596</td>\n",
       "      <td>0.051429</td>\n",
       "      <td>0.011692</td>\n",
       "      <td>0.455976</td>\n",
       "      <td>0.014019</td>\n",
       "      <td>0.082569</td>\n",
       "      <td>0.023968</td>\n",
       "      <td>109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.004657</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.008949</td>\n",
       "      <td>35</td>\n",
       "      <td>0.004072</td>\n",
       "      <td>0.035461</td>\n",
       "      <td>0.007305</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.438300</td>\n",
       "      <td>1.419508</td>\n",
       "      <td>0.006309</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.010899</td>\n",
       "      <td>0.522898</td>\n",
       "      <td>0.008651</td>\n",
       "      <td>0.045872</td>\n",
       "      <td>0.014556</td>\n",
       "      <td>109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.005076</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.009585</td>\n",
       "      <td>35</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>0.042553</td>\n",
       "      <td>0.010076</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.478900</td>\n",
       "      <td>1.382092</td>\n",
       "      <td>0.014650</td>\n",
       "      <td>0.088571</td>\n",
       "      <td>0.025142</td>\n",
       "      <td>0.592159</td>\n",
       "      <td>0.019174</td>\n",
       "      <td>0.119266</td>\n",
       "      <td>0.033037</td>\n",
       "      <td>109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.127660</td>\n",
       "      <td>0.029925</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.143700</td>\n",
       "      <td>1.347125</td>\n",
       "      <td>0.040055</td>\n",
       "      <td>0.165714</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.572168</td>\n",
       "      <td>0.037398</td>\n",
       "      <td>0.211009</td>\n",
       "      <td>0.063536</td>\n",
       "      <td>109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35</td>\n",
       "      <td>0.048276</td>\n",
       "      <td>0.248227</td>\n",
       "      <td>0.080831</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.591200</td>\n",
       "      <td>1.251494</td>\n",
       "      <td>0.030922</td>\n",
       "      <td>0.151429</td>\n",
       "      <td>0.051357</td>\n",
       "      <td>0.625195</td>\n",
       "      <td>0.051173</td>\n",
       "      <td>0.220183</td>\n",
       "      <td>0.083045</td>\n",
       "      <td>109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.002825</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.005141</td>\n",
       "      <td>35</td>\n",
       "      <td>0.033654</td>\n",
       "      <td>0.198582</td>\n",
       "      <td>0.057554</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.257700</td>\n",
       "      <td>1.229175</td>\n",
       "      <td>0.038936</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.063458</td>\n",
       "      <td>0.534879</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.284404</td>\n",
       "      <td>0.121094</td>\n",
       "      <td>109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>0.021053</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.036697</td>\n",
       "      <td>14</td>\n",
       "      <td>0.028818</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.052356</td>\n",
       "      <td>35</td>\n",
       "      <td>0.024460</td>\n",
       "      <td>0.120567</td>\n",
       "      <td>0.040670</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.084800</td>\n",
       "      <td>1.200259</td>\n",
       "      <td>0.048684</td>\n",
       "      <td>0.211429</td>\n",
       "      <td>0.079144</td>\n",
       "      <td>0.520133</td>\n",
       "      <td>0.073222</td>\n",
       "      <td>0.321101</td>\n",
       "      <td>0.119250</td>\n",
       "      <td>109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.056604</td>\n",
       "      <td>14</td>\n",
       "      <td>0.029508</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.052941</td>\n",
       "      <td>35</td>\n",
       "      <td>0.042789</td>\n",
       "      <td>0.191489</td>\n",
       "      <td>0.069948</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.080700</td>\n",
       "      <td>1.080812</td>\n",
       "      <td>0.056849</td>\n",
       "      <td>0.237143</td>\n",
       "      <td>0.091713</td>\n",
       "      <td>0.669148</td>\n",
       "      <td>0.067720</td>\n",
       "      <td>0.275229</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>0.030928</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>14</td>\n",
       "      <td>0.027650</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>35</td>\n",
       "      <td>0.062767</td>\n",
       "      <td>0.312057</td>\n",
       "      <td>0.104513</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.105200</td>\n",
       "      <td>1.163751</td>\n",
       "      <td>0.034556</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.055430</td>\n",
       "      <td>0.540692</td>\n",
       "      <td>0.040323</td>\n",
       "      <td>0.137615</td>\n",
       "      <td>0.062370</td>\n",
       "      <td>109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.041958</td>\n",
       "      <td>14</td>\n",
       "      <td>0.042735</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.074349</td>\n",
       "      <td>35</td>\n",
       "      <td>0.034146</td>\n",
       "      <td>0.148936</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.999100</td>\n",
       "      <td>1.002632</td>\n",
       "      <td>0.064073</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.101144</td>\n",
       "      <td>0.692755</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.275229</td>\n",
       "      <td>0.122699</td>\n",
       "      <td>109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.019802</td>\n",
       "      <td>14</td>\n",
       "      <td>0.028249</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.047170</td>\n",
       "      <td>35</td>\n",
       "      <td>0.078560</td>\n",
       "      <td>0.340426</td>\n",
       "      <td>0.127660</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.942200</td>\n",
       "      <td>0.992626</td>\n",
       "      <td>0.086237</td>\n",
       "      <td>0.282857</td>\n",
       "      <td>0.132176</td>\n",
       "      <td>0.695591</td>\n",
       "      <td>0.097938</td>\n",
       "      <td>0.348624</td>\n",
       "      <td>0.152918</td>\n",
       "      <td>109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.043956</td>\n",
       "      <td>14</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>35</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.382979</td>\n",
       "      <td>0.162896</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.754300</td>\n",
       "      <td>1.121402</td>\n",
       "      <td>0.074257</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.115237</td>\n",
       "      <td>0.561818</td>\n",
       "      <td>0.138138</td>\n",
       "      <td>0.422018</td>\n",
       "      <td>0.208145</td>\n",
       "      <td>109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>0.028986</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.048193</td>\n",
       "      <td>14</td>\n",
       "      <td>0.034749</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>35</td>\n",
       "      <td>0.064706</td>\n",
       "      <td>0.234043</td>\n",
       "      <td>0.101382</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.875100</td>\n",
       "      <td>1.026702</td>\n",
       "      <td>0.084063</td>\n",
       "      <td>0.274286</td>\n",
       "      <td>0.128686</td>\n",
       "      <td>0.601092</td>\n",
       "      <td>0.166090</td>\n",
       "      <td>0.440367</td>\n",
       "      <td>0.241206</td>\n",
       "      <td>109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>0.068493</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.114943</td>\n",
       "      <td>14</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.060837</td>\n",
       "      <td>35</td>\n",
       "      <td>0.071721</td>\n",
       "      <td>0.248227</td>\n",
       "      <td>0.111288</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 30\u001B[0m\n\u001B[1;32m      4\u001B[0m training_args \u001B[39m=\u001B[39m TrainingArguments(\n\u001B[1;32m      5\u001B[0m     output_dir\u001B[39m=\u001B[39m\u001B[39m'\u001B[39m\u001B[39m/home/tiendq/document-layout-analysis/0_model_repository\u001B[39m\u001B[39m'\u001B[39m,          \u001B[39m# output directory\u001B[39;00m\n\u001B[1;32m      6\u001B[0m     num_train_epochs\u001B[39m=\u001B[39m\u001B[39m10\u001B[39m,              \u001B[39m# total number of training epochs\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     18\u001B[0m     resume_from_checkpoint\u001B[39m=\u001B[39m\u001B[39mTrue\u001B[39;00m\n\u001B[1;32m     19\u001B[0m )\n\u001B[1;32m     21\u001B[0m trainer \u001B[39m=\u001B[39m Trainer(\n\u001B[1;32m     22\u001B[0m     model\u001B[39m=\u001B[39mmodel,                         \u001B[39m# the instantiated 🤗 Transformers model to be trained\u001B[39;00m\n\u001B[1;32m     23\u001B[0m     args\u001B[39m=\u001B[39mtraining_args,                  \u001B[39m# training arguments, defined above\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     27\u001B[0m     compute_metrics\u001B[39m=\u001B[39mcompute_metrics,             \u001B[39m# evaluation dataset\u001B[39;00m\n\u001B[1;32m     28\u001B[0m )\n\u001B[0;32m---> 30\u001B[0m trainer\u001B[39m.\u001B[39;49mtrain()\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/transformers/trainer.py:1631\u001B[0m, in \u001B[0;36mTrainer.train\u001B[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[1;32m   1626\u001B[0m     \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mmodel_wrapped \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mmodel\n\u001B[1;32m   1628\u001B[0m inner_training_loop \u001B[39m=\u001B[39m find_executable_batch_size(\n\u001B[1;32m   1629\u001B[0m     \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_inner_training_loop, \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_train_batch_size, args\u001B[39m.\u001B[39mauto_find_batch_size\n\u001B[1;32m   1630\u001B[0m )\n\u001B[0;32m-> 1631\u001B[0m \u001B[39mreturn\u001B[39;00m inner_training_loop(\n\u001B[1;32m   1632\u001B[0m     args\u001B[39m=\u001B[39;49margs,\n\u001B[1;32m   1633\u001B[0m     resume_from_checkpoint\u001B[39m=\u001B[39;49mresume_from_checkpoint,\n\u001B[1;32m   1634\u001B[0m     trial\u001B[39m=\u001B[39;49mtrial,\n\u001B[1;32m   1635\u001B[0m     ignore_keys_for_eval\u001B[39m=\u001B[39;49mignore_keys_for_eval,\n\u001B[1;32m   1636\u001B[0m )\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/transformers/trainer.py:1898\u001B[0m, in \u001B[0;36mTrainer._inner_training_loop\u001B[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[1;32m   1896\u001B[0m         tr_loss_step \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mtraining_step(model, inputs)\n\u001B[1;32m   1897\u001B[0m \u001B[39melse\u001B[39;00m:\n\u001B[0;32m-> 1898\u001B[0m     tr_loss_step \u001B[39m=\u001B[39m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mtraining_step(model, inputs)\n\u001B[1;32m   1900\u001B[0m \u001B[39mif\u001B[39;00m (\n\u001B[1;32m   1901\u001B[0m     args\u001B[39m.\u001B[39mlogging_nan_inf_filter\n\u001B[1;32m   1902\u001B[0m     \u001B[39mand\u001B[39;00m \u001B[39mnot\u001B[39;00m is_torch_tpu_available()\n\u001B[1;32m   1903\u001B[0m     \u001B[39mand\u001B[39;00m (torch\u001B[39m.\u001B[39misnan(tr_loss_step) \u001B[39mor\u001B[39;00m torch\u001B[39m.\u001B[39misinf(tr_loss_step))\n\u001B[1;32m   1904\u001B[0m ):\n\u001B[1;32m   1905\u001B[0m     \u001B[39m# if loss is nan or inf simply add the average of previous logged losses\u001B[39;00m\n\u001B[1;32m   1906\u001B[0m     tr_loss \u001B[39m+\u001B[39m\u001B[39m=\u001B[39m tr_loss \u001B[39m/\u001B[39m (\u001B[39m1\u001B[39m \u001B[39m+\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mstate\u001B[39m.\u001B[39mglobal_step \u001B[39m-\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_globalstep_last_logged)\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/transformers/trainer.py:2640\u001B[0m, in \u001B[0;36mTrainer.training_step\u001B[0;34m(self, model, inputs)\u001B[0m\n\u001B[1;32m   2637\u001B[0m     \u001B[39mreturn\u001B[39;00m loss_mb\u001B[39m.\u001B[39mreduce_mean()\u001B[39m.\u001B[39mdetach()\u001B[39m.\u001B[39mto(\u001B[39mself\u001B[39m\u001B[39m.\u001B[39margs\u001B[39m.\u001B[39mdevice)\n\u001B[1;32m   2639\u001B[0m \u001B[39mwith\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mcompute_loss_context_manager():\n\u001B[0;32m-> 2640\u001B[0m     loss \u001B[39m=\u001B[39m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mcompute_loss(model, inputs)\n\u001B[1;32m   2642\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39margs\u001B[39m.\u001B[39mn_gpu \u001B[39m>\u001B[39m \u001B[39m1\u001B[39m:\n\u001B[1;32m   2643\u001B[0m     loss \u001B[39m=\u001B[39m loss\u001B[39m.\u001B[39mmean()  \u001B[39m# mean() to average on multi-gpu parallel training\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/transformers/trainer.py:2672\u001B[0m, in \u001B[0;36mTrainer.compute_loss\u001B[0;34m(self, model, inputs, return_outputs)\u001B[0m\n\u001B[1;32m   2670\u001B[0m \u001B[39melse\u001B[39;00m:\n\u001B[1;32m   2671\u001B[0m     labels \u001B[39m=\u001B[39m \u001B[39mNone\u001B[39;00m\n\u001B[0;32m-> 2672\u001B[0m outputs \u001B[39m=\u001B[39m model(\u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49minputs)\n\u001B[1;32m   2673\u001B[0m \u001B[39m# Save past state if it exists\u001B[39;00m\n\u001B[1;32m   2674\u001B[0m \u001B[39m# TODO: this needs to be fixed and made cleaner later.\u001B[39;00m\n\u001B[1;32m   2675\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39margs\u001B[39m.\u001B[39mpast_index \u001B[39m>\u001B[39m\u001B[39m=\u001B[39m \u001B[39m0\u001B[39m:\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m \u001B[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m \u001B[39m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mnot\u001B[39;00m (\u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_backward_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_pre_hooks \u001B[39mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[39mor\u001B[39;00m _global_forward_hooks \u001B[39mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[39mreturn\u001B[39;00m forward_call(\u001B[39m*\u001B[39;49m\u001B[39minput\u001B[39;49m, \u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49mkwargs)\n\u001B[1;32m   1195\u001B[0m \u001B[39m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[39m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/transformers/models/layoutlmv2/modeling_layoutlmv2.py:1231\u001B[0m, in \u001B[0;36mLayoutLMv2ForTokenClassification.forward\u001B[0;34m(self, input_ids, bbox, image, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m   1180\u001B[0m \u001B[39m\u001B[39m\u001B[39mr\u001B[39m\u001B[39m\"\"\"\u001B[39;00m\n\u001B[1;32m   1181\u001B[0m \u001B[39mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001B[39;00m\n\u001B[1;32m   1182\u001B[0m \u001B[39m    Labels for computing the token classification loss. Indices should be in `[0, ..., config.num_labels - 1]`.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1226\u001B[0m \u001B[39m```\u001B[39;00m\n\u001B[1;32m   1227\u001B[0m \u001B[39m\"\"\"\u001B[39;00m\n\u001B[1;32m   1229\u001B[0m return_dict \u001B[39m=\u001B[39m return_dict \u001B[39mif\u001B[39;00m return_dict \u001B[39mis\u001B[39;00m \u001B[39mnot\u001B[39;00m \u001B[39mNone\u001B[39;00m \u001B[39melse\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mconfig\u001B[39m.\u001B[39muse_return_dict\n\u001B[0;32m-> 1231\u001B[0m outputs \u001B[39m=\u001B[39m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mlayoutlmv2(\n\u001B[1;32m   1232\u001B[0m     input_ids\u001B[39m=\u001B[39;49minput_ids,\n\u001B[1;32m   1233\u001B[0m     bbox\u001B[39m=\u001B[39;49mbbox,\n\u001B[1;32m   1234\u001B[0m     image\u001B[39m=\u001B[39;49mimage,\n\u001B[1;32m   1235\u001B[0m     attention_mask\u001B[39m=\u001B[39;49mattention_mask,\n\u001B[1;32m   1236\u001B[0m     token_type_ids\u001B[39m=\u001B[39;49mtoken_type_ids,\n\u001B[1;32m   1237\u001B[0m     position_ids\u001B[39m=\u001B[39;49mposition_ids,\n\u001B[1;32m   1238\u001B[0m     head_mask\u001B[39m=\u001B[39;49mhead_mask,\n\u001B[1;32m   1239\u001B[0m     inputs_embeds\u001B[39m=\u001B[39;49minputs_embeds,\n\u001B[1;32m   1240\u001B[0m     output_attentions\u001B[39m=\u001B[39;49moutput_attentions,\n\u001B[1;32m   1241\u001B[0m     output_hidden_states\u001B[39m=\u001B[39;49moutput_hidden_states,\n\u001B[1;32m   1242\u001B[0m     return_dict\u001B[39m=\u001B[39;49mreturn_dict,\n\u001B[1;32m   1243\u001B[0m )\n\u001B[1;32m   1244\u001B[0m \u001B[39mif\u001B[39;00m input_ids \u001B[39mis\u001B[39;00m \u001B[39mnot\u001B[39;00m \u001B[39mNone\u001B[39;00m:\n\u001B[1;32m   1245\u001B[0m     input_shape \u001B[39m=\u001B[39m input_ids\u001B[39m.\u001B[39msize()\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m \u001B[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m \u001B[39m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mnot\u001B[39;00m (\u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_backward_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_pre_hooks \u001B[39mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[39mor\u001B[39;00m _global_forward_hooks \u001B[39mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[39mreturn\u001B[39;00m forward_call(\u001B[39m*\u001B[39;49m\u001B[39minput\u001B[39;49m, \u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49mkwargs)\n\u001B[1;32m   1195\u001B[0m \u001B[39m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[39m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/transformers/models/layoutlmv2/modeling_layoutlmv2.py:913\u001B[0m, in \u001B[0;36mLayoutLMv2Model.forward\u001B[0;34m(self, input_ids, bbox, image, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m    903\u001B[0m     bbox \u001B[39m=\u001B[39m torch\u001B[39m.\u001B[39mzeros(\u001B[39mtuple\u001B[39m(\u001B[39mlist\u001B[39m(input_shape) \u001B[39m+\u001B[39m [\u001B[39m4\u001B[39m]), dtype\u001B[39m=\u001B[39mtorch\u001B[39m.\u001B[39mlong, device\u001B[39m=\u001B[39mdevice)\n\u001B[1;32m    905\u001B[0m text_layout_emb \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_calc_text_embeddings(\n\u001B[1;32m    906\u001B[0m     input_ids\u001B[39m=\u001B[39minput_ids,\n\u001B[1;32m    907\u001B[0m     bbox\u001B[39m=\u001B[39mbbox,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    910\u001B[0m     inputs_embeds\u001B[39m=\u001B[39minputs_embeds,\n\u001B[1;32m    911\u001B[0m )\n\u001B[0;32m--> 913\u001B[0m visual_emb \u001B[39m=\u001B[39m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49m_calc_img_embeddings(\n\u001B[1;32m    914\u001B[0m     image\u001B[39m=\u001B[39;49mimage,\n\u001B[1;32m    915\u001B[0m     bbox\u001B[39m=\u001B[39;49mvisual_bbox,\n\u001B[1;32m    916\u001B[0m     position_ids\u001B[39m=\u001B[39;49mvisual_position_ids,\n\u001B[1;32m    917\u001B[0m )\n\u001B[1;32m    918\u001B[0m final_emb \u001B[39m=\u001B[39m torch\u001B[39m.\u001B[39mcat([text_layout_emb, visual_emb], dim\u001B[39m=\u001B[39m\u001B[39m1\u001B[39m)\n\u001B[1;32m    920\u001B[0m extended_attention_mask \u001B[39m=\u001B[39m final_attention_mask\u001B[39m.\u001B[39munsqueeze(\u001B[39m1\u001B[39m)\u001B[39m.\u001B[39munsqueeze(\u001B[39m2\u001B[39m)\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/transformers/models/layoutlmv2/modeling_layoutlmv2.py:762\u001B[0m, in \u001B[0;36mLayoutLMv2Model._calc_img_embeddings\u001B[0;34m(self, image, bbox, position_ids)\u001B[0m\n\u001B[1;32m    761\u001B[0m \u001B[39mdef\u001B[39;00m \u001B[39m_calc_img_embeddings\u001B[39m(\u001B[39mself\u001B[39m, image, bbox, position_ids):\n\u001B[0;32m--> 762\u001B[0m     visual_embeddings \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mvisual_proj(\u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mvisual(image))\n\u001B[1;32m    763\u001B[0m     position_embeddings \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39membeddings\u001B[39m.\u001B[39mposition_embeddings(position_ids)\n\u001B[1;32m    764\u001B[0m     spatial_position_embeddings \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39membeddings\u001B[39m.\u001B[39m_calc_spatial_position_embeddings(bbox)\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m \u001B[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m \u001B[39m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mnot\u001B[39;00m (\u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_backward_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_pre_hooks \u001B[39mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[39mor\u001B[39;00m _global_forward_hooks \u001B[39mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[39mreturn\u001B[39;00m forward_call(\u001B[39m*\u001B[39;49m\u001B[39minput\u001B[39;49m, \u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49mkwargs)\n\u001B[1;32m   1195\u001B[0m \u001B[39m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[39m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/transformers/models/layoutlmv2/modeling_layoutlmv2.py:591\u001B[0m, in \u001B[0;36mLayoutLMv2VisualBackbone.forward\u001B[0;34m(self, images)\u001B[0m\n\u001B[1;32m    589\u001B[0m \u001B[39mdef\u001B[39;00m \u001B[39mforward\u001B[39m(\u001B[39mself\u001B[39m, images):\n\u001B[1;32m    590\u001B[0m     images_input \u001B[39m=\u001B[39m ((images \u001B[39mif\u001B[39;00m torch\u001B[39m.\u001B[39mis_tensor(images) \u001B[39melse\u001B[39;00m images\u001B[39m.\u001B[39mtensor) \u001B[39m-\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mpixel_mean) \u001B[39m/\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mpixel_std\n\u001B[0;32m--> 591\u001B[0m     features \u001B[39m=\u001B[39m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mbackbone(images_input)\n\u001B[1;32m    592\u001B[0m     features \u001B[39m=\u001B[39m features[\u001B[39mself\u001B[39m\u001B[39m.\u001B[39mout_feature_key]\n\u001B[1;32m    593\u001B[0m     features \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mpool(features)\u001B[39m.\u001B[39mflatten(start_dim\u001B[39m=\u001B[39m\u001B[39m2\u001B[39m)\u001B[39m.\u001B[39mtranspose(\u001B[39m1\u001B[39m, \u001B[39m2\u001B[39m)\u001B[39m.\u001B[39mcontiguous()\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m \u001B[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m \u001B[39m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mnot\u001B[39;00m (\u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_backward_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_pre_hooks \u001B[39mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[39mor\u001B[39;00m _global_forward_hooks \u001B[39mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[39mreturn\u001B[39;00m forward_call(\u001B[39m*\u001B[39;49m\u001B[39minput\u001B[39;49m, \u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49mkwargs)\n\u001B[1;32m   1195\u001B[0m \u001B[39m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[39m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/miniconda3/envs/doclayout/lib/python3.8/site-packages/detectron2/modeling/backbone/fpn.py:139\u001B[0m, in \u001B[0;36mFPN.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    126\u001B[0m \u001B[39mdef\u001B[39;00m \u001B[39mforward\u001B[39m(\u001B[39mself\u001B[39m, x):\n\u001B[1;32m    127\u001B[0m \u001B[39m    \u001B[39m\u001B[39m\"\"\"\u001B[39;00m\n\u001B[1;32m    128\u001B[0m \u001B[39m    Args:\u001B[39;00m\n\u001B[1;32m    129\u001B[0m \u001B[39m        input (dict[str->Tensor]): mapping feature map name (e.g., \"res5\") to\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    137\u001B[0m \u001B[39m            [\"p2\", \"p3\", ..., \"p6\"].\u001B[39;00m\n\u001B[1;32m    138\u001B[0m \u001B[39m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 139\u001B[0m     bottom_up_features \u001B[39m=\u001B[39m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mbottom_up(x)\n\u001B[1;32m    140\u001B[0m     results \u001B[39m=\u001B[39m []\n\u001B[1;32m    141\u001B[0m     prev_features \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mlateral_convs[\u001B[39m0\u001B[39m](bottom_up_features[\u001B[39mself\u001B[39m\u001B[39m.\u001B[39min_features[\u001B[39m-\u001B[39m\u001B[39m1\u001B[39m]])\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m \u001B[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m \u001B[39m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mnot\u001B[39;00m (\u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_backward_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_pre_hooks \u001B[39mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[39mor\u001B[39;00m _global_forward_hooks \u001B[39mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[39mreturn\u001B[39;00m forward_call(\u001B[39m*\u001B[39;49m\u001B[39minput\u001B[39;49m, \u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49mkwargs)\n\u001B[1;32m   1195\u001B[0m \u001B[39m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[39m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/miniconda3/envs/doclayout/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:449\u001B[0m, in \u001B[0;36mResNet.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    447\u001B[0m     outputs[\u001B[39m\"\u001B[39m\u001B[39mstem\u001B[39m\u001B[39m\"\u001B[39m] \u001B[39m=\u001B[39m x\n\u001B[1;32m    448\u001B[0m \u001B[39mfor\u001B[39;00m name, stage \u001B[39min\u001B[39;00m \u001B[39mzip\u001B[39m(\u001B[39mself\u001B[39m\u001B[39m.\u001B[39mstage_names, \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mstages):\n\u001B[0;32m--> 449\u001B[0m     x \u001B[39m=\u001B[39m stage(x)\n\u001B[1;32m    450\u001B[0m     \u001B[39mif\u001B[39;00m name \u001B[39min\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_out_features:\n\u001B[1;32m    451\u001B[0m         outputs[name] \u001B[39m=\u001B[39m x\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m \u001B[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m \u001B[39m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mnot\u001B[39;00m (\u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_backward_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_pre_hooks \u001B[39mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[39mor\u001B[39;00m _global_forward_hooks \u001B[39mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[39mreturn\u001B[39;00m forward_call(\u001B[39m*\u001B[39;49m\u001B[39minput\u001B[39;49m, \u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49mkwargs)\n\u001B[1;32m   1195\u001B[0m \u001B[39m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[39m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/container.py:204\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    202\u001B[0m \u001B[39mdef\u001B[39;00m \u001B[39mforward\u001B[39m(\u001B[39mself\u001B[39m, \u001B[39minput\u001B[39m):\n\u001B[1;32m    203\u001B[0m     \u001B[39mfor\u001B[39;00m module \u001B[39min\u001B[39;00m \u001B[39mself\u001B[39m:\n\u001B[0;32m--> 204\u001B[0m         \u001B[39minput\u001B[39m \u001B[39m=\u001B[39m module(\u001B[39minput\u001B[39;49m)\n\u001B[1;32m    205\u001B[0m     \u001B[39mreturn\u001B[39;00m \u001B[39minput\u001B[39m\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m \u001B[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m \u001B[39m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mnot\u001B[39;00m (\u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_backward_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_pre_hooks \u001B[39mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[39mor\u001B[39;00m _global_forward_hooks \u001B[39mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[39mreturn\u001B[39;00m forward_call(\u001B[39m*\u001B[39;49m\u001B[39minput\u001B[39;49m, \u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49mkwargs)\n\u001B[1;32m   1195\u001B[0m \u001B[39m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[39m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/miniconda3/envs/doclayout/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:195\u001B[0m, in \u001B[0;36mBottleneckBlock.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    194\u001B[0m \u001B[39mdef\u001B[39;00m \u001B[39mforward\u001B[39m(\u001B[39mself\u001B[39m, x):\n\u001B[0;32m--> 195\u001B[0m     out \u001B[39m=\u001B[39m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mconv1(x)\n\u001B[1;32m    196\u001B[0m     out \u001B[39m=\u001B[39m F\u001B[39m.\u001B[39mrelu_(out)\n\u001B[1;32m    198\u001B[0m     out \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mconv2(out)\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m \u001B[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m \u001B[39m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mnot\u001B[39;00m (\u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_backward_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_pre_hooks \u001B[39mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[39mor\u001B[39;00m _global_forward_hooks \u001B[39mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[39mreturn\u001B[39;00m forward_call(\u001B[39m*\u001B[39;49m\u001B[39minput\u001B[39;49m, \u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49mkwargs)\n\u001B[1;32m   1195\u001B[0m \u001B[39m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[39m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/miniconda3/envs/doclayout/lib/python3.8/site-packages/detectron2/layers/wrappers.py:113\u001B[0m, in \u001B[0;36mConv2d.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    107\u001B[0m         \u001B[39mif\u001B[39;00m x\u001B[39m.\u001B[39mnumel() \u001B[39m==\u001B[39m \u001B[39m0\u001B[39m \u001B[39mand\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mtraining:\n\u001B[1;32m    108\u001B[0m             \u001B[39m# https://github.com/pytorch/pytorch/issues/12013\u001B[39;00m\n\u001B[1;32m    109\u001B[0m             \u001B[39massert\u001B[39;00m \u001B[39mnot\u001B[39;00m \u001B[39misinstance\u001B[39m(\n\u001B[1;32m    110\u001B[0m                 \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mnorm, torch\u001B[39m.\u001B[39mnn\u001B[39m.\u001B[39mSyncBatchNorm\n\u001B[1;32m    111\u001B[0m             ), \u001B[39m\"\u001B[39m\u001B[39mSyncBatchNorm does not support empty inputs!\u001B[39m\u001B[39m\"\u001B[39m\n\u001B[0;32m--> 113\u001B[0m x \u001B[39m=\u001B[39m F\u001B[39m.\u001B[39;49mconv2d(\n\u001B[1;32m    114\u001B[0m     x, \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mweight, \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mbias, \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mstride, \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mpadding, \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mdilation, \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mgroups\n\u001B[1;32m    115\u001B[0m )\n\u001B[1;32m    116\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mnorm \u001B[39mis\u001B[39;00m \u001B[39mnot\u001B[39;00m \u001B[39mNone\u001B[39;00m:\n\u001B[1;32m    117\u001B[0m     x \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mnorm(x)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers.data.data_collator import default_data_collator\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='/home/tiendq/document-layout-analysis/0_model_repository',          # output directory\n",
    "    num_train_epochs=10,              # total number of training epochs\n",
    "    per_device_train_batch_size=4,  # batch size per device during training\n",
    "    per_device_eval_batch_size=4,   # batch size for evaluation\n",
    "    # warmup_steps=10,                # number of warmup steps for learning rate scheduler\n",
    "    # weight_decay=0.01, \n",
    "    learning_rate=1e-5,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=5,              # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=5,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"overall_f1\",\n",
    "    resume_from_checkpoint=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=eval_dataset,\n",
    "    data_collator=default_data_collator,\n",
    "    compute_metrics=compute_metrics,             # evaluation dataset\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "225A1flOB9F2"
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "example = train_dataset[0]\n",
    "for k,v in example.items():\n",
    "    print(k,v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3VsO2x51COvX"
   },
   "outputs": [],
   "source": [
    "for id, label in zip(train_dataset[0][\"input_ids\"], train_dataset[0][\"labels\"]):\n",
    "  print(processor.tokenizer.decode([id]), label.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l8cG8_URQH6D"
   },
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# train_data_loader = DataLoader(\n",
    "#     train_dataset,\n",
    "#     batch_size=4,\n",
    "#     shuffle=False,\n",
    "#     num_workers=2\n",
    "# )\n",
    "\n",
    "# test_data_loader = DataLoader(\n",
    "#     test_dataset,\n",
    "#     batch_size=4,\n",
    "#     shuffle=False,\n",
    "#     num_workers=2\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4lXht1X7blqP"
   },
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from transformers import AdamW, LayoutLMv2ForTokenClassification\n",
    "\n",
    "class ModelModule(pl.LightningModule):\n",
    "    def __init__(self, dataset:CocoDataset):\n",
    "        super().__init__()\n",
    "        self.model = LayoutLMv2ForTokenClassification.from_pretrained('microsoft/layoutxlm-base', num_labels=len(dataset.label_list), id2label=dataset.id2label, label2id=dataset.label2id)\n",
    "        self.dataset = dataset\n",
    "    def forward(self, input_ids, attention_mask, bbox, image, labels=None):\n",
    "        return self.model(input_ids, attention_mask=attention_mask, bbox=bbox, image=image, labels=labels)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        labels = batch['labels']\n",
    "        outputs = self(\n",
    "            batch['input_ids'],\n",
    "            batch['attention_mask'],\n",
    "            batch['bbox'],\n",
    "            batch['image'],\n",
    "            labels\n",
    "            )\n",
    "        loss = outputs.loss \n",
    "        self.log('train_loss', loss)\n",
    "        self.log(\"train_overall_f1\", compute_metrics(outputs.logits, labels, self.dataset)['f1'])\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        labels = batch['labels']\n",
    "        outputs = self(\n",
    "            batch['input_ids'],\n",
    "            batch['attention_mask'],\n",
    "            batch['bbox'],\n",
    "            batch['image'],\n",
    "            labels\n",
    "            )\n",
    "        loss = outputs.loss \n",
    "        self.log('val_loss', loss)\n",
    "        self.log(\"val_overall_f1\", compute_metrics(outputs.logits, labels, self.dataset)['f1'])\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return AdamW(self.model.parameters(), lr=5e-5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yAEHeSo4f8xS"
   },
   "outputs": [],
   "source": [
    "model_module = ModelModule(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HjjQDP3LgSLq"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9HJeU95_geC1"
   },
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_accuracy\", min_delta=0.00, patience=3, verbose=False, mode=\"max\")\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    save_last=True,\n",
    "    save_top_k=2,\n",
    "    monitor=\"val_loss\",\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    precision=16,\n",
    "    devices=1,\n",
    "    max_epochs=20,\n",
    "    callbacks=[\n",
    "        model_checkpoint,\n",
    "        early_stop_callback\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JrqJbGmOhIAv"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "trainer.fit(model_module, train_data_loader, test_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NmLGMl8mV1hR"
   },
   "outputs": [],
   "source": [
    "ds[0]['words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JU8g5a1IUvY0"
   },
   "outputs": [],
   "source": [
    "def tokenization(example):\n",
    "    image = Image.open(dataset.root_dir + os.sep + example['file_name']).convert('RGB')\n",
    "    # return processor(\n",
    "    #         np.array(image), \n",
    "    #         example['words'],\n",
    "    #         boxes=torch.tensor(example['boxes']),\n",
    "    #         word_labels=torch.tensor(example['labels_id']),\n",
    "    #         max_length=512,\n",
    "    #         truncation=True,\n",
    "    #         padding=True,\n",
    "    #         # pad_to_multiple_of=8,\n",
    "    #         return_tensors=\"pt\"\n",
    "    #     )\n",
    "    example['image'] = np.array(image)\n",
    "    return example\n",
    "\n",
    "ds = ds.map(tokenization, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D_o2hOB4vHjc"
   },
   "outputs": [],
   "source": [
    "# implement a data colator fo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gjUAjQHKXr2Q"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "optim = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "for epoch in range(3):\n",
    "    for batch in train_loader:\n",
    "        optim.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs[0]\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "doclayout",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "0b7c1f19d704269459faebc556bfcb2d19cd7db89503d98e0af2abc46be05aff"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0296db9d5a744384b4395a10d0ff4251": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3b07b28de74a4d1eaefb4939a9cb1e2c",
      "placeholder": "​",
      "style": "IPY_MODEL_0cf548ff584c4b3a9685549a8733712b",
      "value": " 8/8 [00:00&lt;00:00, 17.70 examples/s]"
     }
    },
    "0ae4e029300944e9b0ba92e858a75858": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0cf548ff584c4b3a9685549a8733712b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0eb83ba3cf5f426284af3b3ef8945ae9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "171b5ee60e9d45b5a0427b19360edb51": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e30f810b1c64ceda9a218442e068d7f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "20d07a579faa47819ee5d88fe573410c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e9b8d589e42444194cb25f3482bdd26": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c94c13ef0c8b4f589e296848795a3495",
       "IPY_MODEL_9bee760419674598a85b98014ccc38e7",
       "IPY_MODEL_6bf4efbcaad84a3c86bde13653f6acd4"
      ],
      "layout": "IPY_MODEL_556f717f09b64019be2719550e8f92e9"
     }
    },
    "379c0138babd4a778a2ef255066a44da": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "3a8fedc7f66348df97247a996e4db1e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1e30f810b1c64ceda9a218442e068d7f",
      "max": 8,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_797674d4425c4b40bccc4df616209fd8",
      "value": 8
     }
    },
    "3b07b28de74a4d1eaefb4939a9cb1e2c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e351492630e4bc59c9b64f126a3d1e9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5143080630f54727b49f868fd302a91e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_aa36543bf5294b4a92b4e00c2b279a4d",
       "IPY_MODEL_c1792af7961b4d9cb035bc3129e3208f",
       "IPY_MODEL_dc32e008b1c84ba197478f6bdd37ed59"
      ],
      "layout": "IPY_MODEL_dc68b7652f4e4111b4d368da5d094336"
     }
    },
    "556f717f09b64019be2719550e8f92e9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "56e17d1cb5214f78932769d664f661eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5b53942300de4e47884f6855dba71774": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5f6cd659aea84ac3bdd429d8726f17e6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "5fcf5d8fa44642ab904531bf0d72bf03": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6bf4efbcaad84a3c86bde13653f6acd4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_20d07a579faa47819ee5d88fe573410c",
      "placeholder": "​",
      "style": "IPY_MODEL_c0cbe38de2724c0ebe8d59c6317721e3",
      "value": " 2/2 [00:00&lt;00:00, 14.15 examples/s]"
     }
    },
    "797674d4425c4b40bccc4df616209fd8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8ae95afd37ac4b339c2047a9d0c2cdce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9bee760419674598a85b98014ccc38e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fddaa84bee894e4091ff90646ced1538",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0eb83ba3cf5f426284af3b3ef8945ae9",
      "value": 2
     }
    },
    "aa36543bf5294b4a92b4e00c2b279a4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d024e956ca494e338e7afd87f34df4d1",
      "placeholder": "​",
      "style": "IPY_MODEL_e1f589b118e144398e026ac3c9570395",
      "value": "Generating train split: "
     }
    },
    "b8640fb1d1b8455598fd47ffd95c6d73": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f41338268d364733a54fdaae085a0711",
       "IPY_MODEL_3a8fedc7f66348df97247a996e4db1e7",
       "IPY_MODEL_0296db9d5a744384b4395a10d0ff4251"
      ],
      "layout": "IPY_MODEL_5f6cd659aea84ac3bdd429d8726f17e6"
     }
    },
    "c0cbe38de2724c0ebe8d59c6317721e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c1792af7961b4d9cb035bc3129e3208f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_379c0138babd4a778a2ef255066a44da",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8ae95afd37ac4b339c2047a9d0c2cdce",
      "value": 1
     }
    },
    "c94c13ef0c8b4f589e296848795a3495": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0ae4e029300944e9b0ba92e858a75858",
      "placeholder": "​",
      "style": "IPY_MODEL_5b53942300de4e47884f6855dba71774",
      "value": "Map: 100%"
     }
    },
    "d024e956ca494e338e7afd87f34df4d1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dc32e008b1c84ba197478f6bdd37ed59": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_171b5ee60e9d45b5a0427b19360edb51",
      "placeholder": "​",
      "style": "IPY_MODEL_5fcf5d8fa44642ab904531bf0d72bf03",
      "value": " 7/0 [00:00&lt;00:00, 47.03 examples/s]"
     }
    },
    "dc68b7652f4e4111b4d368da5d094336": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "e1f589b118e144398e026ac3c9570395": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f41338268d364733a54fdaae085a0711": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4e351492630e4bc59c9b64f126a3d1e9",
      "placeholder": "​",
      "style": "IPY_MODEL_56e17d1cb5214f78932769d664f661eb",
      "value": "Map: 100%"
     }
    },
    "fddaa84bee894e4091ff90646ced1538": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
